{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# http://localhost:8888/notebooks/Documents/AI/scripts/picture_comparison_crop80.ipynbfrom tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,  TensorDataset\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.targets[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # sample = {\"image\": image, \"label\": label}\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset in .nps format\n",
    "\n",
    "data = np.load('crop80_1A0_10A0_5000_5000.npz')\n",
    "x_images = torch.from_numpy(data['arr_0']/255)\n",
    "x_images = torch.transpose(x_images, 1, 3)\n",
    "y_labels = torch.from_numpy(data['arr_1'])\n",
    "len_labels = data['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 80, 80])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_images.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you can change batch size\n",
    "\n",
    "len_dataset = len(y_labels)   \n",
    "    \n",
    "dataset = myDataset(data=x_images.float(), targets=y_labels)\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [int(len_dataset*0.8), len_dataset-int(len_dataset*0.8)])\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size = 50, shuffle = True)\n",
    "test_loader = DataLoader(testset, batch_size = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,testloader,device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            labels=labels.squeeze(1)\n",
    "            # print(predicted)\n",
    "            # print(labels)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # print(correct / total)\n",
    "\n",
    "    return correct / total  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs=50, comment = \"\"):\n",
    "    writer = SummaryWriter(comment)\n",
    "    device = torch.device(\"cpu\")\n",
    "    sum_acc = np.zeros((1,  num_epochs))\n",
    "    sum_loss = sum_acc.copy()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #change learning rate\n",
    "    best_accuracy = 0\n",
    "    best_loss = 100\n",
    "    fig = plt.figure() \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for img_batch, labels_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "    #         print(img_batch.shape)\n",
    "    #         print(labels_batch.shape)\n",
    "            output = model(img_batch.to(device))\n",
    "            loss = criterion(output, labels_batch.to(device).squeeze().long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            images = img_batch.cpu()\n",
    "            label_nums = output.cpu() \n",
    "            accuracy = validate(model,test_loader,device)\n",
    "#             print(accuracy)\n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            print('Best accuracy improved')\n",
    "            torch.save(model.state_dict(), 'model_weights_crop80_1A0_10A0_5000_5000.pth') #name of saved weights\n",
    "        if best_loss > loss.cpu().item():\n",
    "            best_loss = loss.cpu().item()\n",
    "#             print('Best loss improved')\n",
    "\n",
    "        sum_acc[0, epoch] = accuracy\n",
    "        sum_loss[0,epoch] = loss  \n",
    "        writer.add_scalar('Accuracy',accuracy,epoch)\n",
    "        writer.add_scalar('Loss/train',loss.cpu().item(),epoch)\n",
    "        epoch_end = time.time()\n",
    "        print(\"Epoch: {} Loss: {:.3f} Accuracy: {:.3f} Time: {:.4f}s\".format(epoch, loss.item(),accuracy, epoch_end-epoch_start))\n",
    "        \n",
    "        plt.plot(sum_acc[0,0:epoch].T)\n",
    "        plt.show()\n",
    "        writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    return sum_acc, sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=False)\n",
    "model.conv1.weight = torch.nn.Parameter(torch.rand((64,3,7,7)))\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.float()\n",
    "print('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, loss = train(model, 100) #change number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy.T, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss.T, 'b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
